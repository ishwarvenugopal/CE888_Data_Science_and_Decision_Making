{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLP_with_Keras.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOv4ntLbwpFrUFFBrliVWG7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ishwarvenugopal/CE888_Data_Science_and_Decision_Making/blob/master/Deep_Learning/MultiLayerPerceptron_(Keras).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7TDMMTo5oYK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e3ea28ab-09f8-4f30-8c8c-fdc84386b94d"
      },
      "source": [
        "import keras\n",
        "print(keras.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79jUPevBFJrS",
        "colab_type": "text"
      },
      "source": [
        "### Data Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnorJhDE5u4I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRAPTYLO50mX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/ionosphere.csv'"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FAGaIgj52Ss",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(path, header = None)"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtC1s4sr54Qz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "outputId": "ffb6cf07-73f8-497c-cb24-024b1260914f"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.99539</td>\n",
              "      <td>-0.05889</td>\n",
              "      <td>0.85243</td>\n",
              "      <td>0.02306</td>\n",
              "      <td>0.83398</td>\n",
              "      <td>-0.37708</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.03760</td>\n",
              "      <td>0.85243</td>\n",
              "      <td>-0.17755</td>\n",
              "      <td>0.59755</td>\n",
              "      <td>-0.44945</td>\n",
              "      <td>0.60536</td>\n",
              "      <td>-0.38223</td>\n",
              "      <td>0.84356</td>\n",
              "      <td>-0.38542</td>\n",
              "      <td>0.58212</td>\n",
              "      <td>-0.32192</td>\n",
              "      <td>0.56971</td>\n",
              "      <td>-0.29674</td>\n",
              "      <td>0.36946</td>\n",
              "      <td>-0.47357</td>\n",
              "      <td>0.56811</td>\n",
              "      <td>-0.51171</td>\n",
              "      <td>0.41078</td>\n",
              "      <td>-0.46168</td>\n",
              "      <td>0.21266</td>\n",
              "      <td>-0.34090</td>\n",
              "      <td>0.42267</td>\n",
              "      <td>-0.54487</td>\n",
              "      <td>0.18641</td>\n",
              "      <td>-0.45300</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.18829</td>\n",
              "      <td>0.93035</td>\n",
              "      <td>-0.36156</td>\n",
              "      <td>-0.10868</td>\n",
              "      <td>-0.93597</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.04549</td>\n",
              "      <td>0.50874</td>\n",
              "      <td>-0.67743</td>\n",
              "      <td>0.34432</td>\n",
              "      <td>-0.69707</td>\n",
              "      <td>-0.51685</td>\n",
              "      <td>-0.97515</td>\n",
              "      <td>0.05499</td>\n",
              "      <td>-0.62237</td>\n",
              "      <td>0.33109</td>\n",
              "      <td>-1.00000</td>\n",
              "      <td>-0.13151</td>\n",
              "      <td>-0.45300</td>\n",
              "      <td>-0.18056</td>\n",
              "      <td>-0.35734</td>\n",
              "      <td>-0.20332</td>\n",
              "      <td>-0.26569</td>\n",
              "      <td>-0.20468</td>\n",
              "      <td>-0.18401</td>\n",
              "      <td>-0.19040</td>\n",
              "      <td>-0.11593</td>\n",
              "      <td>-0.16626</td>\n",
              "      <td>-0.06288</td>\n",
              "      <td>-0.13738</td>\n",
              "      <td>-0.02447</td>\n",
              "      <td>b</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.03365</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.00485</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.12062</td>\n",
              "      <td>0.88965</td>\n",
              "      <td>0.01198</td>\n",
              "      <td>0.73082</td>\n",
              "      <td>0.05346</td>\n",
              "      <td>0.85443</td>\n",
              "      <td>0.00827</td>\n",
              "      <td>0.54591</td>\n",
              "      <td>0.00299</td>\n",
              "      <td>0.83775</td>\n",
              "      <td>-0.13644</td>\n",
              "      <td>0.75535</td>\n",
              "      <td>-0.08540</td>\n",
              "      <td>0.70887</td>\n",
              "      <td>-0.27502</td>\n",
              "      <td>0.43385</td>\n",
              "      <td>-0.12062</td>\n",
              "      <td>0.57528</td>\n",
              "      <td>-0.40220</td>\n",
              "      <td>0.58984</td>\n",
              "      <td>-0.22145</td>\n",
              "      <td>0.43100</td>\n",
              "      <td>-0.17365</td>\n",
              "      <td>0.60436</td>\n",
              "      <td>-0.24180</td>\n",
              "      <td>0.56045</td>\n",
              "      <td>-0.38238</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.45161</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.71216</td>\n",
              "      <td>-1.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>-1.00000</td>\n",
              "      <td>0.14516</td>\n",
              "      <td>0.54094</td>\n",
              "      <td>-0.39330</td>\n",
              "      <td>-1.00000</td>\n",
              "      <td>-0.54467</td>\n",
              "      <td>-0.69975</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.90695</td>\n",
              "      <td>0.51613</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.20099</td>\n",
              "      <td>0.25682</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.32382</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>b</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>-0.02401</td>\n",
              "      <td>0.94140</td>\n",
              "      <td>0.06531</td>\n",
              "      <td>0.92106</td>\n",
              "      <td>-0.23255</td>\n",
              "      <td>0.77152</td>\n",
              "      <td>-0.16399</td>\n",
              "      <td>0.52798</td>\n",
              "      <td>-0.20275</td>\n",
              "      <td>0.56409</td>\n",
              "      <td>-0.00712</td>\n",
              "      <td>0.34395</td>\n",
              "      <td>-0.27457</td>\n",
              "      <td>0.52940</td>\n",
              "      <td>-0.21780</td>\n",
              "      <td>0.45107</td>\n",
              "      <td>-0.17813</td>\n",
              "      <td>0.05982</td>\n",
              "      <td>-0.35575</td>\n",
              "      <td>0.02309</td>\n",
              "      <td>-0.52879</td>\n",
              "      <td>0.03286</td>\n",
              "      <td>-0.65158</td>\n",
              "      <td>0.13290</td>\n",
              "      <td>-0.53206</td>\n",
              "      <td>0.02431</td>\n",
              "      <td>-0.62197</td>\n",
              "      <td>-0.05707</td>\n",
              "      <td>-0.59573</td>\n",
              "      <td>-0.04608</td>\n",
              "      <td>-0.65697</td>\n",
              "      <td>g</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   0   1        2        3        4   ...       30       31       32       33  34\n",
              "0   1   0  0.99539 -0.05889  0.85243  ...  0.42267 -0.54487  0.18641 -0.45300   g\n",
              "1   1   0  1.00000 -0.18829  0.93035  ... -0.16626 -0.06288 -0.13738 -0.02447   b\n",
              "2   1   0  1.00000 -0.03365  1.00000  ...  0.60436 -0.24180  0.56045 -0.38238   g\n",
              "3   1   0  1.00000 -0.45161  1.00000  ...  0.25682  1.00000 -0.32382  1.00000   b\n",
              "4   1   0  1.00000 -0.02401  0.94140  ... -0.05707 -0.59573 -0.04608 -0.65697   g\n",
              "\n",
              "[5 rows x 35 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5L-oNNZ55fb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "f3f8930b-ef5c-4960-a94a-63c528da3446"
      },
      "source": [
        "X = df.values [:,:-1]\n",
        "y = df.values [:,-1]\n",
        "print(X.shape)\n",
        "print(y.shape)\n",
        "print(type(X[0][0]))\n",
        "print(type(y[0]))"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(351, 34)\n",
            "(351,)\n",
            "<class 'int'>\n",
            "<class 'str'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9edrhmz5-yW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = X.astype('float32')"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzoHmtRU6Cfu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "outputId": "1bd2267e-11b4-4c83-a2db-0ec164ce28e0"
      },
      "source": [
        "y "
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g',\n",
              "       'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b',\n",
              "       'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g',\n",
              "       'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b',\n",
              "       'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g',\n",
              "       'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b',\n",
              "       'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g',\n",
              "       'b', 'g', 'b', 'g', 'b', 'g', 'g', 'b', 'g', 'b', 'g', 'b', 'g',\n",
              "       'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b',\n",
              "       'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g',\n",
              "       'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b',\n",
              "       'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g',\n",
              "       'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b',\n",
              "       'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g',\n",
              "       'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b',\n",
              "       'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g',\n",
              "       'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b',\n",
              "       'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g',\n",
              "       'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b', 'g', 'b',\n",
              "       'g', 'b', 'g', 'b', 'g', 'b', 'g', 'g', 'g', 'g', 'g', 'g', 'g',\n",
              "       'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g',\n",
              "       'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g',\n",
              "       'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g',\n",
              "       'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g',\n",
              "       'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g',\n",
              "       'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g',\n",
              "       'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g', 'g'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tU59ABmZ6Do8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "d67db574-7a50-4422-9ddc-32cf0bc891c6"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "y = LabelEncoder().fit_transform(y)\n",
        "y"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
              "       1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
              "       1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
              "       1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
              "       1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
              "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
              "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
              "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
              "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
              "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
              "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
              "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBWB3wkt6GyZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "94bc7074-1b98-4f22-a6a1-55b1ee2cbea5"
      },
      "source": [
        "print(type(y[0]))"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.int64'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nImo-zQ_6JhO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = y.astype('float32')"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgstiunO6MXP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "7342d89b-217c-45fe-8f80-55e7a5da35fb"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.33, random_state = 42)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(235, 34)\n",
            "(235,)\n",
            "(116, 34)\n",
            "(116,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9aCW7sEFdSt",
        "colab_type": "text"
      },
      "source": [
        "### Model Definition:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WaLmzkr6dCD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import Adam, SGD"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyUWrs4o6sdw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def define_model(input_shape):\n",
        "  model = Sequential()\n",
        "  model.add(Dense(10,input_dim = input_shape, kernel_initializer= 'uniform',activation='relu' ))\n",
        "  model.add(Dense(8, activation='relu', kernel_initializer='uniform'))\n",
        "  model.add(Dense(1,activation='sigmoid'))\n",
        "  model.summary()\n",
        "  # opt = Adam(learning_rate=0.01)\n",
        "  opt = SGD(learning_rate=0.01, momentum=0.9)\n",
        "  model.compile(loss = 'binary_crossentropy', optimizer= opt, metrics = ['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jps9NDGj9l0z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "baa6a2a6-42ac-4a81-b6c3-e9c2502b6f24"
      },
      "source": [
        "model = define_model(X.shape[1])"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_25 (Dense)             (None, 10)                350       \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 8)                 88        \n",
            "_________________________________________________________________\n",
            "dense_27 (Dense)             (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 447\n",
            "Trainable params: 447\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xq62Bs3sFkdo",
        "colab_type": "text"
      },
      "source": [
        "### Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0AzO-VB_8Zt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import h5py\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QD-rz5Pw-lzI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cebd5ced-49ad-4017-c4e4-c49ff623d09d"
      },
      "source": [
        "mc = ModelCheckpoint('best_model.h5', monitor = 'val_loss', save_best_only = True)\n",
        "early = EarlyStopping(monitor = 'val_loss', patience = 50)\n",
        "history = model.fit(X_train, y_train, epochs = 100, batch_size = 10, validation_split= 0.3, callbacks=[early,mc], verbose = 1)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 164 samples, validate on 71 samples\n",
            "Epoch 1/100\n",
            "164/164 [==============================] - 0s 596us/step - loss: 0.6841 - accuracy: 0.6037 - val_loss: 0.6548 - val_accuracy: 0.6901\n",
            "Epoch 2/100\n",
            "164/164 [==============================] - 0s 152us/step - loss: 0.6580 - accuracy: 0.6402 - val_loss: 0.6259 - val_accuracy: 0.6901\n",
            "Epoch 3/100\n",
            "164/164 [==============================] - 0s 152us/step - loss: 0.6510 - accuracy: 0.6402 - val_loss: 0.6150 - val_accuracy: 0.6901\n",
            "Epoch 4/100\n",
            "164/164 [==============================] - 0s 153us/step - loss: 0.6464 - accuracy: 0.6402 - val_loss: 0.6058 - val_accuracy: 0.6901\n",
            "Epoch 5/100\n",
            "164/164 [==============================] - 0s 155us/step - loss: 0.6352 - accuracy: 0.6402 - val_loss: 0.5790 - val_accuracy: 0.6901\n",
            "Epoch 6/100\n",
            "164/164 [==============================] - 0s 180us/step - loss: 0.6141 - accuracy: 0.6402 - val_loss: 0.5512 - val_accuracy: 0.6901\n",
            "Epoch 7/100\n",
            "164/164 [==============================] - 0s 149us/step - loss: 0.5834 - accuracy: 0.6402 - val_loss: 0.5171 - val_accuracy: 0.6901\n",
            "Epoch 8/100\n",
            "164/164 [==============================] - 0s 160us/step - loss: 0.5400 - accuracy: 0.6402 - val_loss: 0.4733 - val_accuracy: 0.6901\n",
            "Epoch 9/100\n",
            "164/164 [==============================] - 0s 163us/step - loss: 0.4913 - accuracy: 0.7378 - val_loss: 0.4367 - val_accuracy: 0.7887\n",
            "Epoch 10/100\n",
            "164/164 [==============================] - 0s 152us/step - loss: 0.4409 - accuracy: 0.8049 - val_loss: 0.4425 - val_accuracy: 0.8873\n",
            "Epoch 11/100\n",
            "164/164 [==============================] - 0s 167us/step - loss: 0.4062 - accuracy: 0.8659 - val_loss: 0.4052 - val_accuracy: 0.8873\n",
            "Epoch 12/100\n",
            "164/164 [==============================] - 0s 149us/step - loss: 0.3604 - accuracy: 0.8902 - val_loss: 0.3986 - val_accuracy: 0.8873\n",
            "Epoch 13/100\n",
            "164/164 [==============================] - 0s 147us/step - loss: 0.3340 - accuracy: 0.9024 - val_loss: 0.3798 - val_accuracy: 0.8873\n",
            "Epoch 14/100\n",
            "164/164 [==============================] - 0s 149us/step - loss: 0.3069 - accuracy: 0.9024 - val_loss: 0.3869 - val_accuracy: 0.8732\n",
            "Epoch 15/100\n",
            "164/164 [==============================] - 0s 159us/step - loss: 0.2867 - accuracy: 0.9085 - val_loss: 0.3865 - val_accuracy: 0.8592\n",
            "Epoch 16/100\n",
            "164/164 [==============================] - 0s 172us/step - loss: 0.2720 - accuracy: 0.9146 - val_loss: 0.3774 - val_accuracy: 0.8592\n",
            "Epoch 17/100\n",
            "164/164 [==============================] - 0s 163us/step - loss: 0.2631 - accuracy: 0.9329 - val_loss: 0.3849 - val_accuracy: 0.8592\n",
            "Epoch 18/100\n",
            "164/164 [==============================] - 0s 152us/step - loss: 0.2582 - accuracy: 0.9329 - val_loss: 0.4041 - val_accuracy: 0.8592\n",
            "Epoch 19/100\n",
            "164/164 [==============================] - 0s 151us/step - loss: 0.2313 - accuracy: 0.9268 - val_loss: 0.3878 - val_accuracy: 0.8732\n",
            "Epoch 20/100\n",
            "164/164 [==============================] - 0s 158us/step - loss: 0.2279 - accuracy: 0.9268 - val_loss: 0.4109 - val_accuracy: 0.8592\n",
            "Epoch 21/100\n",
            "164/164 [==============================] - 0s 176us/step - loss: 0.2037 - accuracy: 0.9573 - val_loss: 0.3894 - val_accuracy: 0.8732\n",
            "Epoch 22/100\n",
            "164/164 [==============================] - 0s 182us/step - loss: 0.2096 - accuracy: 0.9329 - val_loss: 0.3855 - val_accuracy: 0.8592\n",
            "Epoch 23/100\n",
            "164/164 [==============================] - 0s 162us/step - loss: 0.1861 - accuracy: 0.9451 - val_loss: 0.3735 - val_accuracy: 0.8732\n",
            "Epoch 24/100\n",
            "164/164 [==============================] - 0s 149us/step - loss: 0.1791 - accuracy: 0.9512 - val_loss: 0.3882 - val_accuracy: 0.8592\n",
            "Epoch 25/100\n",
            "164/164 [==============================] - 0s 164us/step - loss: 0.1706 - accuracy: 0.9512 - val_loss: 0.3876 - val_accuracy: 0.8732\n",
            "Epoch 26/100\n",
            "164/164 [==============================] - 0s 175us/step - loss: 0.1550 - accuracy: 0.9634 - val_loss: 0.3902 - val_accuracy: 0.8873\n",
            "Epoch 27/100\n",
            "164/164 [==============================] - 0s 173us/step - loss: 0.1524 - accuracy: 0.9634 - val_loss: 0.3952 - val_accuracy: 0.8451\n",
            "Epoch 28/100\n",
            "164/164 [==============================] - 0s 162us/step - loss: 0.1411 - accuracy: 0.9512 - val_loss: 0.4608 - val_accuracy: 0.8732\n",
            "Epoch 29/100\n",
            "164/164 [==============================] - 0s 156us/step - loss: 0.1634 - accuracy: 0.9512 - val_loss: 0.3849 - val_accuracy: 0.8732\n",
            "Epoch 30/100\n",
            "164/164 [==============================] - 0s 154us/step - loss: 0.1555 - accuracy: 0.9634 - val_loss: 0.3877 - val_accuracy: 0.8873\n",
            "Epoch 31/100\n",
            "164/164 [==============================] - 0s 163us/step - loss: 0.1387 - accuracy: 0.9634 - val_loss: 0.4016 - val_accuracy: 0.8732\n",
            "Epoch 32/100\n",
            "164/164 [==============================] - 0s 171us/step - loss: 0.1344 - accuracy: 0.9573 - val_loss: 0.4029 - val_accuracy: 0.9014\n",
            "Epoch 33/100\n",
            "164/164 [==============================] - 0s 166us/step - loss: 0.1229 - accuracy: 0.9634 - val_loss: 0.3636 - val_accuracy: 0.9014\n",
            "Epoch 34/100\n",
            "164/164 [==============================] - 0s 145us/step - loss: 0.1232 - accuracy: 0.9634 - val_loss: 0.4197 - val_accuracy: 0.8873\n",
            "Epoch 35/100\n",
            "164/164 [==============================] - 0s 156us/step - loss: 0.1136 - accuracy: 0.9634 - val_loss: 0.4011 - val_accuracy: 0.9014\n",
            "Epoch 36/100\n",
            "164/164 [==============================] - 0s 156us/step - loss: 0.1112 - accuracy: 0.9695 - val_loss: 0.4606 - val_accuracy: 0.8732\n",
            "Epoch 37/100\n",
            "164/164 [==============================] - 0s 170us/step - loss: 0.1313 - accuracy: 0.9634 - val_loss: 0.4294 - val_accuracy: 0.8873\n",
            "Epoch 38/100\n",
            "164/164 [==============================] - 0s 201us/step - loss: 0.1030 - accuracy: 0.9695 - val_loss: 0.4325 - val_accuracy: 0.8732\n",
            "Epoch 39/100\n",
            "164/164 [==============================] - 0s 159us/step - loss: 0.0853 - accuracy: 0.9878 - val_loss: 0.4657 - val_accuracy: 0.8873\n",
            "Epoch 40/100\n",
            "164/164 [==============================] - 0s 159us/step - loss: 0.0999 - accuracy: 0.9634 - val_loss: 0.4531 - val_accuracy: 0.9014\n",
            "Epoch 41/100\n",
            "164/164 [==============================] - 0s 151us/step - loss: 0.0832 - accuracy: 0.9756 - val_loss: 0.4383 - val_accuracy: 0.9014\n",
            "Epoch 42/100\n",
            "164/164 [==============================] - 0s 176us/step - loss: 0.0796 - accuracy: 0.9756 - val_loss: 0.4495 - val_accuracy: 0.8873\n",
            "Epoch 43/100\n",
            "164/164 [==============================] - 0s 150us/step - loss: 0.0740 - accuracy: 0.9756 - val_loss: 0.4647 - val_accuracy: 0.9014\n",
            "Epoch 44/100\n",
            "164/164 [==============================] - 0s 161us/step - loss: 0.0756 - accuracy: 0.9817 - val_loss: 0.4760 - val_accuracy: 0.8873\n",
            "Epoch 45/100\n",
            "164/164 [==============================] - 0s 199us/step - loss: 0.0754 - accuracy: 0.9817 - val_loss: 0.4706 - val_accuracy: 0.9014\n",
            "Epoch 46/100\n",
            "164/164 [==============================] - 0s 186us/step - loss: 0.0942 - accuracy: 0.9756 - val_loss: 0.4938 - val_accuracy: 0.9014\n",
            "Epoch 47/100\n",
            "164/164 [==============================] - 0s 173us/step - loss: 0.0720 - accuracy: 0.9817 - val_loss: 0.5703 - val_accuracy: 0.9014\n",
            "Epoch 48/100\n",
            "164/164 [==============================] - 0s 161us/step - loss: 0.0767 - accuracy: 0.9878 - val_loss: 0.5527 - val_accuracy: 0.8732\n",
            "Epoch 49/100\n",
            "164/164 [==============================] - 0s 159us/step - loss: 0.0687 - accuracy: 0.9817 - val_loss: 0.5302 - val_accuracy: 0.9014\n",
            "Epoch 50/100\n",
            "164/164 [==============================] - 0s 153us/step - loss: 0.0774 - accuracy: 0.9817 - val_loss: 0.5263 - val_accuracy: 0.8873\n",
            "Epoch 51/100\n",
            "164/164 [==============================] - 0s 157us/step - loss: 0.1041 - accuracy: 0.9573 - val_loss: 0.6181 - val_accuracy: 0.8873\n",
            "Epoch 52/100\n",
            "164/164 [==============================] - 0s 163us/step - loss: 0.0562 - accuracy: 0.9878 - val_loss: 0.5491 - val_accuracy: 0.8732\n",
            "Epoch 53/100\n",
            "164/164 [==============================] - 0s 168us/step - loss: 0.0562 - accuracy: 0.9878 - val_loss: 0.6133 - val_accuracy: 0.8873\n",
            "Epoch 54/100\n",
            "164/164 [==============================] - 0s 154us/step - loss: 0.0977 - accuracy: 0.9573 - val_loss: 0.6058 - val_accuracy: 0.8732\n",
            "Epoch 55/100\n",
            "164/164 [==============================] - 0s 167us/step - loss: 0.0638 - accuracy: 0.9817 - val_loss: 0.5661 - val_accuracy: 0.9014\n",
            "Epoch 56/100\n",
            "164/164 [==============================] - 0s 157us/step - loss: 0.0528 - accuracy: 0.9878 - val_loss: 0.5750 - val_accuracy: 0.9014\n",
            "Epoch 57/100\n",
            "164/164 [==============================] - 0s 164us/step - loss: 0.0536 - accuracy: 0.9878 - val_loss: 0.6311 - val_accuracy: 0.9014\n",
            "Epoch 58/100\n",
            "164/164 [==============================] - 0s 157us/step - loss: 0.0565 - accuracy: 0.9939 - val_loss: 0.5941 - val_accuracy: 0.9014\n",
            "Epoch 59/100\n",
            "164/164 [==============================] - 0s 170us/step - loss: 0.0477 - accuracy: 0.9939 - val_loss: 0.5937 - val_accuracy: 0.9014\n",
            "Epoch 60/100\n",
            "164/164 [==============================] - 0s 180us/step - loss: 0.0436 - accuracy: 0.9939 - val_loss: 0.6454 - val_accuracy: 0.8592\n",
            "Epoch 61/100\n",
            "164/164 [==============================] - 0s 192us/step - loss: 0.0475 - accuracy: 0.9878 - val_loss: 0.6161 - val_accuracy: 0.8732\n",
            "Epoch 62/100\n",
            "164/164 [==============================] - 0s 156us/step - loss: 0.0433 - accuracy: 0.9939 - val_loss: 0.6496 - val_accuracy: 0.8451\n",
            "Epoch 63/100\n",
            "164/164 [==============================] - 0s 158us/step - loss: 0.0413 - accuracy: 0.9939 - val_loss: 0.6457 - val_accuracy: 0.8592\n",
            "Epoch 64/100\n",
            "164/164 [==============================] - 0s 157us/step - loss: 0.0415 - accuracy: 0.9939 - val_loss: 0.6432 - val_accuracy: 0.9014\n",
            "Epoch 65/100\n",
            "164/164 [==============================] - 0s 157us/step - loss: 0.0414 - accuracy: 0.9939 - val_loss: 0.6767 - val_accuracy: 0.8451\n",
            "Epoch 66/100\n",
            "164/164 [==============================] - 0s 153us/step - loss: 0.0432 - accuracy: 0.9939 - val_loss: 0.6462 - val_accuracy: 0.8873\n",
            "Epoch 67/100\n",
            "164/164 [==============================] - 0s 167us/step - loss: 0.0365 - accuracy: 0.9939 - val_loss: 0.6954 - val_accuracy: 0.8451\n",
            "Epoch 68/100\n",
            "164/164 [==============================] - 0s 156us/step - loss: 0.0383 - accuracy: 0.9939 - val_loss: 0.7181 - val_accuracy: 0.8451\n",
            "Epoch 69/100\n",
            "164/164 [==============================] - 0s 156us/step - loss: 0.0427 - accuracy: 0.9939 - val_loss: 0.6627 - val_accuracy: 0.9014\n",
            "Epoch 70/100\n",
            "164/164 [==============================] - 0s 174us/step - loss: 0.0388 - accuracy: 0.9939 - val_loss: 0.7027 - val_accuracy: 0.8732\n",
            "Epoch 71/100\n",
            "164/164 [==============================] - 0s 155us/step - loss: 0.0414 - accuracy: 0.9939 - val_loss: 0.7303 - val_accuracy: 0.8451\n",
            "Epoch 72/100\n",
            "164/164 [==============================] - 0s 162us/step - loss: 0.0379 - accuracy: 0.9939 - val_loss: 0.7455 - val_accuracy: 0.8451\n",
            "Epoch 73/100\n",
            "164/164 [==============================] - 0s 197us/step - loss: 0.0344 - accuracy: 0.9939 - val_loss: 0.7097 - val_accuracy: 0.8592\n",
            "Epoch 74/100\n",
            "164/164 [==============================] - 0s 171us/step - loss: 0.0324 - accuracy: 0.9939 - val_loss: 0.7155 - val_accuracy: 0.9155\n",
            "Epoch 75/100\n",
            "164/164 [==============================] - 0s 161us/step - loss: 0.0372 - accuracy: 0.9939 - val_loss: 0.7793 - val_accuracy: 0.8310\n",
            "Epoch 76/100\n",
            "164/164 [==============================] - 0s 168us/step - loss: 0.0343 - accuracy: 0.9939 - val_loss: 0.7585 - val_accuracy: 0.8451\n",
            "Epoch 77/100\n",
            "164/164 [==============================] - 0s 151us/step - loss: 0.0382 - accuracy: 0.9939 - val_loss: 0.7199 - val_accuracy: 0.8732\n",
            "Epoch 78/100\n",
            "164/164 [==============================] - 0s 158us/step - loss: 0.0373 - accuracy: 0.9939 - val_loss: 0.7711 - val_accuracy: 0.8451\n",
            "Epoch 79/100\n",
            "164/164 [==============================] - 0s 155us/step - loss: 0.0288 - accuracy: 0.9939 - val_loss: 0.8182 - val_accuracy: 0.8451\n",
            "Epoch 80/100\n",
            "164/164 [==============================] - 0s 161us/step - loss: 0.0279 - accuracy: 0.9939 - val_loss: 0.8343 - val_accuracy: 0.8451\n",
            "Epoch 81/100\n",
            "164/164 [==============================] - 0s 162us/step - loss: 0.0304 - accuracy: 0.9939 - val_loss: 0.8776 - val_accuracy: 0.8310\n",
            "Epoch 82/100\n",
            "164/164 [==============================] - 0s 174us/step - loss: 0.0269 - accuracy: 0.9939 - val_loss: 0.7793 - val_accuracy: 0.8592\n",
            "Epoch 83/100\n",
            "164/164 [==============================] - 0s 175us/step - loss: 0.0338 - accuracy: 0.9939 - val_loss: 0.9237 - val_accuracy: 0.8310\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqK2yiNGFrI9",
        "colab_type": "text"
      },
      "source": [
        "### Evaluating the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSFMmxPe_9ID",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrWiLOgrCUct",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = load_model('best_model.h5')"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3-uAxG4CZA5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "020be3f2-0692-4179-8366-faabc740f69d"
      },
      "source": [
        "__, acc = model.evaluate(X_test, y_test, verbose =1)\n",
        "print(\"Accuracy : {}\".format(acc))"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "116/116 [==============================] - 0s 183us/step\n",
            "Accuracy : 0.8362069129943848\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACmTkZprFw-b",
        "colab_type": "text"
      },
      "source": [
        "### Making Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxf-IxJGCmQo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "outputId": "41b4a5fd-ce97-4c45-a9d2-06c338d93bd2"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "row = np.array((1,0,0.99539,-0.05889,0.85243,0.02306,0.83398,-0.37708,1,0.03760,0.85243,-0.17755,0.59755,-0.44945,0.60536,-0.38223,0.84356,-0.38542,0.58212,-0.32192,0.56971,-0.29674,0.36946,-0.47357,0.56811,-0.51171,0.41078,-0.46168,0.21266,-0.34090,0.42267,-0.54487,0.18641,-0.45300))\n",
        "print(row.shape)\n",
        "print(row)\n",
        "row = row.reshape(-1,len(row))\n",
        "print(row.shape)\n",
        "print(row)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(34,)\n",
            "[ 1.       0.       0.99539 -0.05889  0.85243  0.02306  0.83398 -0.37708\n",
            "  1.       0.0376   0.85243 -0.17755  0.59755 -0.44945  0.60536 -0.38223\n",
            "  0.84356 -0.38542  0.58212 -0.32192  0.56971 -0.29674  0.36946 -0.47357\n",
            "  0.56811 -0.51171  0.41078 -0.46168  0.21266 -0.3409   0.42267 -0.54487\n",
            "  0.18641 -0.453  ]\n",
            "(1, 34)\n",
            "[[ 1.       0.       0.99539 -0.05889  0.85243  0.02306  0.83398 -0.37708\n",
            "   1.       0.0376   0.85243 -0.17755  0.59755 -0.44945  0.60536 -0.38223\n",
            "   0.84356 -0.38542  0.58212 -0.32192  0.56971 -0.29674  0.36946 -0.47357\n",
            "   0.56811 -0.51171  0.41078 -0.46168  0.21266 -0.3409   0.42267 -0.54487\n",
            "   0.18641 -0.453  ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMbhoBCXCzs8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6b88b99e-7bfa-4fc1-94d9-073f1fe0baa4"
      },
      "source": [
        "yhat = model.predict(row)\n",
        "print(\"Predicted value: {} (i.e Class = {})\".format(yhat,yhat.round()))"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted value: [[0.98389566]] (i.e Class = [[1.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fwgbyQ2DNyU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}